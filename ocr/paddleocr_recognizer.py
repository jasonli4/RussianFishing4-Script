import os
import sys
import threading
import cv2
import numpy as np
import re
from typing import Optional, Tuple, List
from paddleocr import PaddleOCR
from logger import logger
from dxgi import dxgi

def get_resource_path(relative_path):
    base_dir = getattr(sys, '_MEIPASS', os.path.dirname(os.path.abspath(__file__)))
    return os.path.join(base_dir, relative_path)

class PaddleocrRecognizer:
    def __init__(self, region: Tuple[int, int, int, int]):
        """
        åˆå§‹åŒ–åæ ‡è¯†åˆ«å™¨
        region: (left, top, width, height)
        """
        self.region = region

        self.ocr = PaddleOCR(
        use_doc_orientation_classify=False, 
        use_doc_unwarping=False, 
        use_textline_orientation=False,
        text_detection_model_name="PP-OCRv5_mobile_det",
        text_recognition_model_name="PP-OCRv5_mobile_rec",
        cpu_threads	=1,
        text_detection_model_dir=get_resource_path("./weights/PP-OCRv5_mobile_det"),
        text_recognition_model_dir=get_resource_path("./weights/PP-OCRv5_mobile_rec"),
        # text_detection_model_dir=get_resource_path("./weights/PP-OCRv5_server_det"),
        # text_recognition_model_dir=get_resource_path("./weights/PP-OCRv5_server_rec"),
        # enable_mkldnn=False
        )
        
        self.coord_pattern = re.compile(r'(\d+)\s*[:ï¼š]\s*(\d+)')  # æ”¯æŒ 123:456ã€123ï¼š456

        self.lock = threading.Lock()

        # æ—¥å¿—
        self.logger =logger

    def safe_ocr(self, image):
        with self.lock:
            return self.ocr.predict(image)

    def parse_coordinate(self, text: str) -> Optional[Tuple[int, int]]:
        """
        å°è¯•è§£æåæ ‡æ ¼å¼ X:Yï¼Œå…è®¸è¯†åˆ«é”™è¯¯å¯¼è‡´çš„ X.Y æˆ– Xï¼šYã€‚
        å…ˆå»æ‰ç©ºæ ¼å†åŒ¹é…ï¼Œä»…æ”¯æŒçº¯åæ ‡æ ¼å¼ã€‚
        """
        coord_pattern = re.compile(r'^(\d+)[.:ï¼š](\d+)$')
        text = text.replace(' ', '')  # å»é™¤æ‰€æœ‰ç©ºæ ¼
        match = coord_pattern.match(text)
        if match:
            try:
                x = int(match.group(1))
                y = int(match.group(2))
                return x, y
            except ValueError:
                self.logger.debug(f"åæ ‡æ•°å­—è½¬æ¢å¤±è´¥: {text}")
                return None
        else:
            self.logger.debug(f"ä¸åŒ¹é…åæ ‡æ ¼å¼: {text}")
            return None

    def screenshot(self, region: Optional[dict] = None, fill_black: bool = False, is_preprocess=False,scale = 2.0):
      
        # 1. è·å–æˆªå›¾åŒºåŸŸ
        if region is None:
            left, top, width, height = self.region
        else:
            left, top, width, height = region["left"], region["top"], region["width"], region["height"]

        monitor = {"top": top, "left": left, "width": width, "height": height}
        sct_img = dxgi.grab_region(monitor)
        img_cv = np.array(sct_img)
        img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGRA2BGR)
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)

        base_dir = os.path.dirname(os.path.abspath(__file__))

        if fill_black:
            template_names = ["info_icon1.png", "info_icon2.png"]
            threshold = 0.85
            matched_areas = []

            for template_name in template_names:
                full_path = os.path.join(base_dir, "images", template_name)
                if not os.path.exists(full_path):
                    self.logger.warning(f"[è­¦å‘Š] æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
                    continue

                template = cv2.imread(full_path, 0)
                if template is None:
                    self.logger.warning(f"[è·³è¿‡] æ— æ³•è¯»å–æ¨¡æ¿å›¾åƒ: {full_path}")
                    continue

                w, h = template.shape[::-1]
                result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF_NORMED)
                loc = np.where(result >= threshold)

                for pt in zip(*loc[::-1]):
                    if any(abs(pt[0] - x) < w and abs(pt[1] - y) < h for (x, y) in matched_areas):
                        continue
                    matched_areas.append(pt)

                    # # æ¶‚é»‘
                    # cv2.rectangle(img_cv, pt, (pt[0] + w, pt[1] + h), (0, 0, 0), -1)

                    # ç”¨å‘¨å›´é¢œè‰²å¡«å……ï¼ˆåŸå®ç°ï¼‰
                    roi = img_cv[pt[1]:pt[1]+h, pt[0]:pt[0]+w]
                    mean_color = cv2.mean(roi)[:3]
                    fill_color = tuple(map(int, mean_color))
                    cv2.rectangle(img_cv, pt, (pt[0] + w, pt[1] + h), fill_color, -1)

                    self.logger.debug(f"[é®æŒ¡] ä½¿ç”¨æ¨¡æ¿ {template_name} é®æŒ¡å›¾æ ‡ at: {pt}")

            if matched_areas:
                self.logger.debug(f"[é®æŒ¡] å…±é®æŒ¡ {len(matched_areas)} ä¸ªå›¾æ ‡åŒºåŸŸ")
            else:
                self.logger.debug(f"[é®æŒ¡] æœªå‘ç°éœ€è¦é®æŒ¡çš„å›¾æ ‡")

        # æ”¾å¤§
        img_cv = cv2.resize(img_cv, (int(img_cv.shape[1] * scale), int(img_cv.shape[0] * scale)), interpolation=cv2.INTER_LANCZOS4)
        
        if is_preprocess:
            # é¢„å¤„ç†
            gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            # binary = cv2.dilate(binary, np.ones((2, 2), np.uint8), iterations=1)
            img_cv = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)

        # # ä¿å­˜è°ƒè¯•å›¾åƒ
        # debug_dir = os.path.join(base_dir, "debug_images")
        # os.makedirs(debug_dir, exist_ok=True)
        # # æ—¶é—´æˆ³ç²¾ç¡®åˆ°å¾®ç§’ï¼Œé¿å…åŒä¸€ç§’å†…è¦†ç›–
        # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        # debug_path = os.path.join(debug_dir, f"processed_{timestamp}.png")
        # if cv2.imwrite(debug_path, img_cv):
        #     self.logger.info(f"[è°ƒè¯•] å·²ä¿å­˜å¤„ç†å›¾åƒ: {debug_path}")
        # else:
        #     self.logger.error(f"[è°ƒè¯•] ä¿å­˜å›¾åƒå¤±è´¥: {debug_path}")

        return img_cv
    
    def recognize_text_from_black_bg(self, region: dict, min_confidence: float = 0.8, fill_black: bool = False, is_preprocess=False,scale = 2.0) -> List[str]:
        """
        è¯†åˆ«é»‘åº•ç™½å­—åŒºåŸŸçš„æ‰€æœ‰æ–‡æœ¬ï¼ˆä¸­è‹±æ–‡æ•°å­—æ··åˆï¼‰ï¼Œæ”¾å¤§ä¸¤å€å¹¶ä¿å­˜æˆªå›¾ã€‚
        :param region: æˆªå›¾åŒºåŸŸ dictï¼Œä¾‹å¦‚ {"left": 100, "top": 200, "width": 300, "height": 100}
        :param min_confidence: æœ€å°ç½®ä¿¡åº¦è¿‡æ»¤é˜ˆå€¼
        :return: æ–‡æœ¬åˆ—è¡¨
        """
        try:
            processed = self.screenshot(region=region, fill_black=fill_black, is_preprocess=is_preprocess,scale=scale)

            if processed is None or processed.size == 0:
                self.logger.warning("æˆªå›¾ä¸ºç©º")
                return []

            # OCR è¯†åˆ«ï¼ˆæ”¯æŒä¸­è‹±æ–‡æ•°å­—ï¼‰
            try:
                results = self.safe_ocr(processed)
            except Exception as e:
                self.logger.error(f"OCR æ‰§è¡Œå¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡è¯†åˆ«: {e}")
                return []

            if not results:
                self.logger.info("æœªè¯†åˆ«å‡ºä»»ä½•æ–‡æœ¬")
                return []

            # æå–æ–‡æœ¬
            texts = []
            for item in results:
                rec_texts = item.get("rec_texts", [])
                rec_scores = item.get("rec_scores", [])
                for text, conf in zip(rec_texts, rec_scores):
                    # self.logger.info(f"[è¯†åˆ«] æ–‡æœ¬: '{text}', ç½®ä¿¡åº¦: {conf:.2f}")
                    if conf >= min_confidence:
                        texts.append(text)

            return texts

        except Exception:
            self.logger.exception("è¯†åˆ«é»‘åº•ç™½å­—æ–‡æœ¬å¤±è´¥")
            return []

    def recognize_text_from_black_bg_first(self, region: dict, min_confidence: float = 0.8, fill_black: bool = False, is_preprocess=False, scale = 2.0) -> Optional[str]:
        """
        é»‘åº•ç™½å­—è¯†åˆ«ï¼šè¿”å›ç½®ä¿¡åº¦æœ€é«˜çš„æ–‡æœ¬ï¼ˆæ»¡è¶³ min_confidenceï¼‰ï¼Œå¤±è´¥è¿”å› None
        :param region: æˆªå›¾åŒºåŸŸ dictï¼Œä¾‹å¦‚ {"left": 100, "top": 200, "width": 300, "height": 100}
        :param min_confidence: æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼
        :return: æœ€ä½³æ–‡æœ¬å­—ç¬¦ä¸² æˆ– None
        """
        try:
            processed = self.screenshot(region=region, fill_black=fill_black, is_preprocess=is_preprocess,scale=scale)

            if processed is None or processed.size == 0:
                self.logger.warning("æˆªå›¾ä¸ºç©º")
                return ''

            # OCR è¯†åˆ«
            try:
                results = self.safe_ocr(processed)
            except Exception as e:
                self.logger.error(f"OCR æ‰§è¡Œå¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡è¯†åˆ«: {e}")
                return None

            if not results:
                self.logger.info("æœªè¯†åˆ«å‡ºä»»ä½•æ–‡æœ¬")
                return ''
            # ç­›é€‰ç½®ä¿¡åº¦æœ€é«˜çš„æ–‡æœ¬
            best_text = ''
            best_conf = 0.0
            for item in results:
                rec_texts = item.get("rec_texts", [])
                rec_scores = item.get("rec_scores", [])
                for text, conf in zip(rec_texts, rec_scores):
                    # self.logger.info(f"[è¯†åˆ«] æ–‡æœ¬: '{text}', ç½®ä¿¡åº¦: {conf:.2f}")
                    if conf >= min_confidence and conf > best_conf:
                        best_conf = conf
                        best_text = text

            return best_text if best_text else ''

        except Exception:
            self.logger.exception("è¯†åˆ«é»‘åº•æ–‡æœ¬ï¼ˆå•æ¡ï¼‰å¤±è´¥")
            return ''
    
    def recognize_coordinate_once(self, min_confidence: float = 0.8) -> Optional[List[int]]:
        """æ‰§è¡Œä¸€æ¬¡åæ ‡è¯†åˆ«ï¼Œè¿”å› [X, Y] æˆ– Noneï¼ˆç½®ä¿¡åº¦ä»…ç”¨äºæ‰“å°ï¼‰"""
        try:
            image = self.screenshot()
            if image is None:
                self.logger.warning("âŒ æˆªå›¾è¿”å› None")
                return None
            if not isinstance(image, np.ndarray):
                self.logger.error(f"âŒ æˆªå›¾è¿”å›é ndarray ç±»å‹: {type(image)}")
                return None
            if image.size == 0:
                self.logger.warning("âŒ æˆªå›¾å†…å®¹ä¸ºç©ºï¼ˆsize == 0ï¼‰")
                return None

            try:
                results = self.safe_ocr(image)
            except Exception as e:
                self.logger.error(f"OCR æ‰§è¡Œå¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡è¯†åˆ«: {e}", exc_info=True)
                return None

            if not results:
                return None

            coords = []
            confs = []

            for item in results:
                rec_texts = item.get("rec_texts", [])
                rec_scores = item.get("rec_scores", [])
                for text, conf in zip(rec_texts, rec_scores):
                    parsed = self.parse_coordinate(text)
                    if parsed:
                        coords.append(parsed)
                        confs.append(conf)

            if not coords:
                return None

            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„åæ ‡
            best_index = confs.index(max(confs))
            best_coord = coords[best_index]
            best_conf = confs[best_index]

            if best_conf > min_confidence:
                return [best_coord[0], best_coord[1]]
            else:
                self.logger.info(f"åæ ‡ç½®ä¿¡åº¦ {best_conf:.2f} ä½äºé˜ˆå€¼ {min_confidence}")
                return None

        except Exception:
            self.logger.exception("ğŸ”¥ recognize_coordinate_once æ•´ä½“å¼‚å¸¸ï¼ˆå¯èƒ½é OCR å†…éƒ¨é—®é¢˜ï¼‰")
            return None
